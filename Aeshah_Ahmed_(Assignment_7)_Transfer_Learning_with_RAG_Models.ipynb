{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with RAG Models\n",
        "----\n",
        "**Objective**: In this notebook, you will experiment with a QA RAG model on the climate_fever dataset using the Haystack framework. You will get to go through the whole process of fitting the parts of a RAG model together, and learn how to prompt it with queries to get answers from the provided dataset.\n",
        "\n",
        "NOTE: Make sure to change the runtime from CPU to TPU or GPU for faster training"
      ],
      "metadata": {
        "id": "43hOmsSmsdsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries\n",
        "Install the Haystack (for colab) and Datasets libraries"
      ],
      "metadata": {
        "id": "GFOp78HWQKKX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rLW-gBSXVsvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a152b7-bfd7-4d19-c0b7-0a96fe79ce02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: farm-haystack[colab] in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
            "Requirement already satisfied: boilerpy3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (1.0.7)\n",
            "Requirement already satisfied: events in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (0.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (0.26.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (4.19.2)\n",
            "Requirement already satisfied: lazy-imports==0.3.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (0.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (9.0.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (4.2.0)\n",
            "Requirement already satisfied: posthog in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (3.4.1)\n",
            "Requirement already satisfied: prompthub-py==4.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (4.0.0)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (1.10.14)\n",
            "Requirement already satisfied: quantulum3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (0.9.0)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (2.31.0)\n",
            "Requirement already satisfied: requests-cache<1.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (0.9.8)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (1.4.1.post1)\n",
            "Requirement already satisfied: sseclient-py in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (1.8.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (4.66.2)\n",
            "Requirement already satisfied: transformers==4.36.2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (4.36.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack[colab]) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->farm-haystack[colab]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->farm-haystack[colab]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->farm-haystack[colab]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->farm-haystack[colab]) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->farm-haystack[colab]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->farm-haystack[colab]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2->farm-haystack[colab]) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2->farm-haystack[colab]) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab]) (2024.2.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab]) (23.2.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab]) (23.2.3)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab]) (1.4.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab]) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab]) (1.0.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab]) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->farm-haystack[colab]) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab]) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab]) (0.17.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab]) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab]) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab]) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab]) (2.2.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab]) (7.0.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab]) (0.5.13)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[colab]) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2->farm-haystack[colab]) (2023.6.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->quantulum3->farm-haystack[colab]) (0.6.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install farm-haystack[colab]\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dataset\n",
        "----\n",
        "In this section, we will use as an example the climate_fever dataset. The dataset consists of 1535 rows of claims about climate change, and they either refute or support climate change, with some claims being neutral. We will build with a specific topic in mind so that we can get more accurate answers, and keep in mind that bigger datasets with open topics can also be used."
      ],
      "metadata": {
        "id": "cWFb0ReWWK-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**: Use the \"load_dataset\" function to load the \"climate_fever\" dataset with the \"test\" split."
      ],
      "metadata": {
        "id": "uf_GSEF9NkHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "climate_fever_dataset = load_dataset(\"climate_fever\")\n",
        "claims = climate_fever_dataset[\"test\"][\"claim\"]\n",
        "evidences = climate_fever_dataset[\"test\"][\"evidences\"]"
      ],
      "metadata": {
        "id": "GKGpONh5i_3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f0d4c5-f569-44f3-ebee-a25f16383c68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formatting and Writing Documents\n",
        "----\n",
        "First, we need to extract, format and write the documents from our chosen dataset so that we can later build our QA Pipeline. This Pipeline will facilitate the process of building our RAG model and getting answers from it.\n",
        "\n",
        "Keep in mind that for this notebook we will focus on how to build the pipeline with the simplest configurations. Feel free to experiment with different parameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "amMMwyd4aWjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**: Use the write_documents method to save the formatted documents into document_storage"
      ],
      "metadata": {
        "id": "wUPCVg7DcVXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "\n",
        "# Extract and format the documents from the dataset\n",
        "formatted_documents = []\n",
        "for claim, evidence_list in zip(claims, evidences):\n",
        "    # Combine all evidence texts into a single string\n",
        "    evidence_text = \"\"\n",
        "    for evidence_dict in evidence_list:\n",
        "        # Check if the evidence dictionary contains the key for text\n",
        "        if \"text\" in evidence_dict:\n",
        "            evidence_text += evidence_dict[\"text\"] + \" \"\n",
        "    formatted_doc = {\n",
        "        \"question\": claim,\n",
        "        \"context\": evidence_text.strip(),\n",
        "        \"content\": claim + \" \" + evidence_text.strip()\n",
        "    }\n",
        "    formatted_documents.append(formatted_doc)\n",
        "\n",
        "document_storage = InMemoryDocumentStore(use_bm25=True)\n",
        "\n",
        "# Write the documents to the document store\n",
        "document_storage.write_documents(formatted_documents)\n"
      ],
      "metadata": {
        "id": "AKLcvGBGcSG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5062b5a4-cc5e-42e9-fd53-bc7e306c5436"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating BM25 representation...: 100%|██████████| 1535/1535 [00:00<00:00, 83174.09 docs/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Retriever\n",
        "----\n",
        "We need to prepare our Retriever node of our pipeline. It will be responsible to get the documents from our document storage, so that they can be used by the Language Model later. We will the BM25Retriever provided by haystack, as it is the recommended Retriever for begginners."
      ],
      "metadata": {
        "id": "kEw3rT_Ifu9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**: Create the BM25Retriever using the document_storage created earlier, with a top_k of value 2"
      ],
      "metadata": {
        "id": "HoeETHTAgiMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "\n",
        "# Create the BM25Retriever with the specified top_k value\n",
        "retriever = BM25Retriever(document_store=document_storage, top_k=2)\n"
      ],
      "metadata": {
        "id": "-oEBHLR0pIdn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Language Model\n",
        "----\n",
        "Now, we will prepare our Language Model using the prompt node. We need to first create our prompt, and for that, Haystack requires a specific structure. We will then define our desired language model alongside the prompt template we created. When creating this template, we need to Parse the output to a format that Haystack can use."
      ],
      "metadata": {
        "id": "88xvymE1hGoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**: Define the prompt node using PromptNode with the model name as \"google/flan-t5-large\" and the default prompt template as the created \"rag_prompt\""
      ],
      "metadata": {
        "id": "7rcCzztZiGYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
        "\n",
        "# Define the rag_prompt template\n",
        "rag_prompt = PromptTemplate(\n",
        "    prompt=\"\"\"Create comprehensive answers from the related text given the questions.\n",
        "    Provide a clear and concise response that displays the key points and information presented in the related text.\n",
        "    Your answer should be in your own words and be no longer than 50 words.\n",
        "    \\n\\n Related text: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\",\n",
        "    output_parser=AnswerParser(),\n",
        ")\n",
        "\n",
        "# Create the PromptNode with the model name and the rag_prompt template\n",
        "prompt_node = PromptNode(model_name_or_path=\"google/flan-t5-large\",default_prompt_template=rag_prompt)"
      ],
      "metadata": {
        "id": "y8H34FFcpPtf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting our Pipeline Together\n",
        "----\n",
        "Finally, we are going to put our pipeline nodes together. For that we will use the Pipeline function from haystack. With the pipeline ready you will be able to ask it questions and get answers"
      ],
      "metadata": {
        "id": "etr1NjR-i-Vm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5**: Add the retriever node and prompt_node created in the previous steps to the Pipeline using the add_node function. Hint: you need to provide the inputs to each of these nodes."
      ],
      "metadata": {
        "id": "Ydu0gj7ojjEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import Pipeline\n",
        "\n",
        "# Create a new Pipeline\n",
        "pipe = Pipeline()\n",
        "\n",
        "pipe.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
        "pipe.add_node(component=prompt_node, name=\"prompt_node\", inputs=[\"retriever\"])"
      ],
      "metadata": {
        "id": "VtgT2ZjNpUka"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Asking the RAG Model Questions\n",
        "----\n",
        "We use the pipeline .run() method to ask a question. Since the output provided by our Prompt Node is a Haystack object, we retrieve in the way provided inside the print() function."
      ],
      "metadata": {
        "id": "gLS6VxZcwUFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pipe.run(query=\"When did global warming start\")\n",
        "\n",
        "print(output[\"answers\"][0].answer)"
      ],
      "metadata": {
        "id": "JjT-ORZKpWkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3426574c-9f4f-4065-8800-d13cb9185555"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 20th century global warming did not start until 1910.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output1 = pipe.run(query=\"What is the biggest damaging factor for the climate?\")\n",
        "\n",
        "print(output1[\"answers\"][0].answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mowm34d72gZU",
        "outputId": "95551bd1-a76a-430b-9e6d-3d8bc0daad04"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Burping cows are more damaging to the climate than all the cars on this planet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output2 = pipe.run(query=\"Who is most responsible for pollution\")\n",
        "\n",
        "print(output2[\"answers\"][0].answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1ZtuPWm2sjc",
        "outputId": "97fe58c2-d80d-4ac0-dcf2-e3b2709c9741"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The IPCC 95% confidence that humans are responsible for most of the current global warming is simply a summary of the peer-reviewed scientific research.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output3 = pipe.run(query=\"What are some clean energy sources?\")\n",
        "\n",
        "print(output3[\"answers\"][0].answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvblehQf2sVv",
        "outputId": "ef7f0dd2-5dd9-4cea-e210-019ab8eff370"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solar, wind and geothermal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output4 = pipe.run(query=\"How much does the average temperature of our planet rise per decade?\")\n",
        "\n",
        "print(output4[\"answers\"][0].answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxs8jYsH2sE6",
        "outputId": "e426b10e-a113-4a67-ea26-e3bc1be191cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average temperature of our planet has risen by around 1.62F (0.9C).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here are some other examples you can use\n",
        "examples = [\n",
        "    \"Who is most responsible for pollution\",\n",
        "    \"What is the biggest damaging factor for the climate?\",\n",
        "    \"What are some clean energy sources?\",\n",
        "    \"How much does the average temperature of our planet rise per decade?\"\n",
        "]"
      ],
      "metadata": {
        "id": "y1QY-cruqFwf"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}